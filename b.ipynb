{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da8da30b",
   "metadata": {},
   "source": [
    "# BASIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fa635",
   "metadata": {},
   "source": [
    "## ê²½ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e339fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Path ì •ë¦¬\n",
    "DATA_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data\")\n",
    "BASE_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_sam3/\")\n",
    "CSV_PATH = DATA_DIR / \"metadata.csv\"\n",
    "\n",
    "# CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "target = 0                             # ì›í•˜ëŠ” í–‰ ì¸ë±ìŠ¤ ì„¤ì •\n",
    "COMMON_PATH = df.loc[target,\"common_path\"]   # COMMON_PATH ì¶”ì¶œ\n",
    "\n",
    "VIDEO_PTH = df.loc[target,\"video_path\"]\n",
    "N_FRAMES = df.loc[target,\"n_frames\"]                    # í”„ë ˆì„ ìˆ˜ ì¶”ì¶œ\n",
    "\n",
    "FRAME_DIR = DATA_DIR / \"1_FRAME\" / COMMON_PATH          # í”„ë ˆì„ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "KPT_DIR = DATA_DIR / \"2_KEYPOINTS\" / COMMON_PATH        # í‚¤í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "MP4_PATH = DATA_DIR / \"3_MP4\" / f\"{COMMON_PATH}.mp4\"     # MP4 ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •    \n",
    "INTERP_DIR = DATA_DIR / \"4_INTERP_DATA\" /COMMON_PATH    # ë³´ê°„ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "OUTPUT_PATH = DATA_DIR / \"test\"\n",
    "\n",
    "CHECKPOINT_DIR = DATA_DIR / \"checkpoints/SAM3\"\n",
    "CHECKPOINT_PT = CHECKPOINT_DIR / \"sam3.pt\"\n",
    "\n",
    "print(COMMON_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481c431",
   "metadata": {},
   "source": [
    "### ë””ë²„ê¹…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d73821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ DEBUGGING REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. ê¸°ë³¸ ê²½ë¡œ ë° CSV í™•ì¸\n",
    "print(f\"\\n[1] ê¸°ë³¸ ê²½ë¡œ ì„¤ì • í™•ì¸\")\n",
    "print(f\"   - DATA_DIR: {DATA_DIR} [{'âœ… Exists' if DATA_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - BASE_DIR: {BASE_DIR} [{'âœ… Exists' if BASE_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - CSV_PATH: {CSV_PATH} [{'âœ… Exists' if CSV_PATH.exists() else 'âŒ Missing'}]\")\n",
    "\n",
    "# 2. íƒ€ê²Ÿ ë°ì´í„° ì •ë³´ (DataFrame ì¶”ì¶œ ê°’)\n",
    "print(f\"\\n[2] Target Data Info (Index: {target})\")\n",
    "print(f\"   - COMMON_PATH: {COMMON_PATH}\")\n",
    "print(f\"   - N_FRAMES   : {N_FRAMES} (Type: {type(N_FRAMES).__name__})\")\n",
    "print(f\"   - VIDEO_PTH (Raw): {VIDEO_PTH}\")\n",
    "\n",
    "# 3. ì£¼ìš” ë””ë ‰í† ë¦¬ ë° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ê²€ì¦\n",
    "# VIDEO_PTHëŠ” ë¬¸ìì—´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ Path ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ í™•ì¸\n",
    "video_path_obj = Path(VIDEO_PTH)\n",
    "print(f\"\\n[3] ì£¼ìš” ê²½ë¡œ ìœ íš¨ì„± ê²€ì‚¬\")\n",
    "print(f\"   - Video File   : {video_path_obj} [{'âœ… Exists' if video_path_obj.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - MP4_PATH     : {MP4_PATH} [{'âœ… Exists' if MP4_PATH.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - FRAME_DIR    : {FRAME_DIR} [{'âœ… Exists' if FRAME_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - KPT_DIR      : {KPT_DIR} [{'âœ… Exists' if KPT_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - INTERP_DIR   : {INTERP_DIR} [{'âœ… Exists' if INTERP_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - OUTPUT_PATH  : {OUTPUT_PATH} [{'âœ… Exists' if OUTPUT_PATH.exists() else 'âš ï¸ Will be created'}]\")\n",
    "\n",
    "# 4. ì²´í¬í¬ì¸íŠ¸ í™•ì¸\n",
    "print(f\"\\n[4] ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ í™•ì¸\")\n",
    "print(f\"   - Checkpoint Dir : {CHECKPOINT_DIR} [{'âœ… Exists' if CHECKPOINT_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - Checkpoint File: {CHECKPOINT_PT} [{'âœ… Exists' if CHECKPOINT_PT.exists() else 'âŒ Missing'}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# í•„ìˆ˜ ê²½ë¡œê°€ ì—†ì„ ê²½ìš° ê²½ê³  ë°œìƒ (ì„ íƒ ì‚¬í•­)\n",
    "if not video_path_obj.exists():\n",
    "    print(\"ğŸš¨ WARNING: ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\")\n",
    "if not CHECKPOINT_PT.exists():\n",
    "    print(\"ğŸš¨ WARNING: ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼(sam3.pt)ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e4c44",
   "metadata": {},
   "source": [
    "## kptì—ì„œ Boundary Box ê°€ì§€ê³  ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ada14cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(KPT_DIR / \"000000.json\", 'r') as f:\n",
    "    kpt_data = json.load(f)\n",
    "\n",
    "ori_bbox = kpt_data['instance_info'][0]['bbox'][0]\n",
    "ori_bbox = np.array(ori_bbox,dtype=np.float32)\n",
    "\n",
    "kpt_width, kpt_height = 1280, 720\n",
    "\n",
    "rel_box = [[\n",
    "    ori_bbox[0] / kpt_width,\n",
    "    ori_bbox[1] / kpt_height,\n",
    "    ori_bbox[2] / kpt_width,\n",
    "    ori_bbox[3] / kpt_height\n",
    "]]\n",
    "rel_box = np.array(rel_box,dtype=np.float32)\n",
    "\n",
    "print(\"Original BBox:\", ori_bbox)\n",
    "print(\"Relative BBox:\", rel_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62179f7",
   "metadata": {},
   "source": [
    "## SAM3 ëª¨ë¸ ë¹Œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f895e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sam3.model_builder import build_sam3_video_model\n",
    "\n",
    "sam3_model = build_sam3_video_model(checkpoint_path=CHECKPOINT_PT)  # SAM3 ë¹„ë””ì˜¤ ëª¨ë¸ ë¹Œë“œ\n",
    "predictor = sam3_model.tracker                                      # SAM3 ë¹„ë””ì˜¤ ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”\n",
    "predictor.backbone = sam3_model.detector.backbone                   # ë°±ë³¸ ì„¤ì •\n",
    "\n",
    "print(\"SAM3 ë¹„ë””ì˜¤ ëª¨ë¸ê³¼ ì˜ˆì¸¡ê¸°ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aca1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_state = predictor.init_state(video_path=VIDEO_PTH)    # ë¹„ë””ì˜¤ ì¶”ë¡  ìƒíƒœ ì´ˆê¸°í™”\n",
    "predictor.clear_all_points_in_video(inference_state)            # ë¹„ë””ì˜¤ì˜ ëª¨ë“  í¬ì¸íŠ¸ ì§€ìš°ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b44d79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7495320",
   "metadata": {},
   "source": [
    "## ë¹„ë””ì˜¤ ê°€ì§€ê³  ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22322ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# load the frames for visualization\n",
    "cap = cv2.VideoCapture(VIDEO_PTH)       # ë¹„ë””ì˜¤ ì—´ê¸°\n",
    "video_frames_for_vis = []               #\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    video_frames_for_vis.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "cap.release()\n",
    "frame0 = video_frames_for_vis[0]\n",
    "\n",
    "width, height = frame0.shape[1], frame0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc333ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sam3.visualization_utils import show_box, show_mask\n",
    "ann_frame_idx = 0  # the frame index we interact with\n",
    "ann_obj_id = 4  # give a unique id to each object we interact with (it can be any integers)\n",
    "\n",
    "width = 1920\n",
    "height = 1080\n",
    "\n",
    "_, out_obj_ids, low_res_masks, video_res_masks  = predictor.add_new_points_or_box(\n",
    "    inference_state=inference_state,\n",
    "    frame_idx=ann_frame_idx,\n",
    "    obj_id=ann_obj_id,\n",
    "    box=rel_box,\n",
    ")\n",
    "\n",
    "box=np.array([[ \n",
    "    rel_box[0][0] * width,\n",
    "    rel_box[0][1] * height,\n",
    "    rel_box[0][2] * width,\n",
    "    rel_box[0][3] * height\n",
    "]], dtype=np.float32)\n",
    "\n",
    "\n",
    "# # show the results on the current (interacted) frame\n",
    "# plt.figure(figsize=(9, 6))\n",
    "# plt.title(f\"frame {ann_frame_idx}\")\n",
    "# plt.imshow(video_frames_for_vis[ann_frame_idx])\n",
    "# show_box(box[0], plt.gca())\n",
    "# show_mask((video_res_masks[0] > 0.0).cpu().numpy(), plt.gca(), obj_id=ann_obj_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb7fe06",
   "metadata": {},
   "source": [
    "## segmentation ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98cf40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "# run propagation throughout the video and collect the results in a dict\n",
    "video_segments = {}  # video_segments contains the per-frame segmentation results\n",
    "for frame_idx, obj_ids, low_res_masks, video_res_masks, obj_scores in predictor.propagate_in_video(inference_state, start_frame_idx=0, max_frame_num_to_track=N_FRAMES, reverse=False, propagate_preflight=True):\n",
    "    video_segments[frame_idx] = {\n",
    "        out_obj_id: (video_res_masks[i] > 0.0).cpu().numpy()\n",
    "        for i, out_obj_id in enumerate(out_obj_ids)\n",
    "    }\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Propagation completed in {elapsed_time:.2f} seconds for {N_FRAMES} frames.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba566b",
   "metadata": {},
   "source": [
    "### JSON ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390074e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "SAVE_DIR = OUTPUT_PATH / COMMON_PATH\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "JSON_SAVE_PATH = SAVE_DIR / \"video_segments.json\"\n",
    "\n",
    "def mask_to_bbox(mask):\n",
    "    \"\"\"Convert a binary mask to bounding box [x_min, y_min, x_max, y_max].\"\"\"\n",
    "    # ğŸ’¡ [ìˆ˜ì •] ì°¨ì›ì´ 3ì°¨ì›(1, H, W)ì´ë©´ 2ì°¨ì›(H, W)ìœ¼ë¡œ ì••ì¶•\n",
    "    if mask.ndim == 3:\n",
    "        mask = mask.squeeze()\n",
    "        \n",
    "    ys, xs = np.where(mask)\n",
    "    if len(xs) == 0 or len(ys) == 0:\n",
    "        return [0, 0, 0, 0]  # No mask found\n",
    "    \n",
    "    x_min, x_max = xs.min(), xs.max()\n",
    "    y_min, y_max = ys.min(), ys.max()\n",
    "    \n",
    "    # JSON ì €ì¥ì„ ìœ„í•´ numpy intë¥¼ python intë¡œ ë³€í™˜\n",
    "    return [int(x_min), int(y_min), int(x_max), int(y_max)]\n",
    "\n",
    "json_output = {}\n",
    "\n",
    "# ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•´ tqdm ì‚¬ìš© ê¶Œì¥\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"ğŸ”„ JSON ë³€í™˜ ë° ì €ì¥ ì¤€ë¹„ ì¤‘...\")\n",
    "\n",
    "for frame_idx, segments in tqdm(video_segments.items()):\n",
    "    json_output[str(frame_idx)] = {} # JSON í‚¤ëŠ” ë¬¸ìì—´ì´ì–´ì•¼ ì•ˆì „í•¨\n",
    "    \n",
    "    for obj_id, mask in segments.items():\n",
    "        # ë§ˆìŠ¤í¬ ì°¨ì› ì •ë¦¬ (ì—¬ê¸°ì„œë„ ë¯¸ë¦¬ í•´ì¤˜ë„ ë¨)\n",
    "        if mask.ndim == 3:\n",
    "            mask = mask.squeeze()\n",
    "            \n",
    "        bbox = mask_to_bbox(mask)\n",
    "        \n",
    "        json_output[str(frame_idx)][str(obj_id)] = {\n",
    "            \"bbox\": bbox,\n",
    "        }\n",
    "\n",
    "try:\n",
    "    print(f\"ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì‹œì‘: {JSON_SAVE_PATH}\")\n",
    "    \n",
    "    with open(JSON_SAVE_PATH, 'w') as f:\n",
    "        json.dump(json_output, f) # indent=4ë¥¼ ë¹¼ë©´ ìš©ëŸ‰ì´ ì¤„ì–´ë“­ë‹ˆë‹¤.\n",
    "        \n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ! : {JSON_SAVE_PATH}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì €ì¥ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa016d95",
   "metadata": {},
   "source": [
    "### ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd142c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# render the segmentation results every few frames\n",
    "vis_frame_stride = 30\n",
    "plt.close(\"all\")\n",
    "for out_frame_idx in range(0, len(video_frames_for_vis), vis_frame_stride):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(f\"frame {out_frame_idx}\")\n",
    "    plt.imshow(video_frames_for_vis[out_frame_idx])\n",
    "    for out_obj_id, out_mask in video_segments[out_frame_idx].items():\n",
    "        show_mask(out_mask, plt.gca(), obj_id=out_obj_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a364980",
   "metadata": {},
   "source": [
    "# Long Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0fee04",
   "metadata": {},
   "source": [
    "## ê²½ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Path ì •ë¦¬\n",
    "DATA_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data\")\n",
    "BASE_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_sam3/\")\n",
    "CSV_PATH = DATA_DIR / \"metadata.csv\"\n",
    "\n",
    "# CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "target = 0                             # ì›í•˜ëŠ” í–‰ ì¸ë±ìŠ¤ ì„¤ì •\n",
    "COMMON_PATH = df.loc[target,\"common_path\"]   # COMMON_PATH ì¶”ì¶œ\n",
    "\n",
    "VIDEO_PTH = df.loc[target,\"video_path\"]\n",
    "N_FRAMES = df.loc[target,\"n_frames\"]                    # í”„ë ˆì„ ìˆ˜ ì¶”ì¶œ\n",
    "\n",
    "FRAME_DIR = DATA_DIR / \"1_FRAME\" / COMMON_PATH          # í”„ë ˆì„ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "KPT_DIR = DATA_DIR / \"2_KEYPOINTS\" / COMMON_PATH        # í‚¤í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "MP4_PATH = DATA_DIR / \"3_MP4\" / f\"{COMMON_PATH}.mp4\"     # MP4 ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •    \n",
    "INTERP_DIR = DATA_DIR / \"4_INTERP_DATA\" /COMMON_PATH    # ë³´ê°„ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "OUTPUT_PATH = DATA_DIR / \"test\"\n",
    "\n",
    "CHECKPOINT_DIR = DATA_DIR / \"checkpoints/SAM3\"\n",
    "CHECKPOINT_PT = CHECKPOINT_DIR / \"sam3.pt\"\n",
    "\n",
    "print(COMMON_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f479d8",
   "metadata": {},
   "source": [
    "### ë””ë²„ê¹…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9effa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ DEBUGGING REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. ê¸°ë³¸ ê²½ë¡œ ë° CSV í™•ì¸\n",
    "print(f\"\\n[1] ê¸°ë³¸ ê²½ë¡œ ì„¤ì • í™•ì¸\")\n",
    "print(f\"   - DATA_DIR: {DATA_DIR} [{'âœ… Exists' if DATA_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - BASE_DIR: {BASE_DIR} [{'âœ… Exists' if BASE_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - CSV_PATH: {CSV_PATH} [{'âœ… Exists' if CSV_PATH.exists() else 'âŒ Missing'}]\")\n",
    "\n",
    "# 2. íƒ€ê²Ÿ ë°ì´í„° ì •ë³´ (DataFrame ì¶”ì¶œ ê°’)\n",
    "print(f\"\\n[2] Target Data Info (Index: {target})\")\n",
    "print(f\"   - COMMON_PATH: {COMMON_PATH}\")\n",
    "print(f\"   - N_FRAMES   : {N_FRAMES} (Type: {type(N_FRAMES).__name__})\")\n",
    "print(f\"   - VIDEO_PTH (Raw): {VIDEO_PTH}\")\n",
    "\n",
    "# 3. ì£¼ìš” ë””ë ‰í† ë¦¬ ë° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ê²€ì¦\n",
    "# VIDEO_PTHëŠ” ë¬¸ìì—´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ Path ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ í™•ì¸\n",
    "video_path_obj = Path(VIDEO_PTH)\n",
    "print(f\"\\n[3] ì£¼ìš” ê²½ë¡œ ìœ íš¨ì„± ê²€ì‚¬\")\n",
    "print(f\"   - Video File   : {video_path_obj} [{'âœ… Exists' if video_path_obj.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - MP4_PATH     : {MP4_PATH} [{'âœ… Exists' if MP4_PATH.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - FRAME_DIR    : {FRAME_DIR} [{'âœ… Exists' if FRAME_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - KPT_DIR      : {KPT_DIR} [{'âœ… Exists' if KPT_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - INTERP_DIR   : {INTERP_DIR} [{'âœ… Exists' if INTERP_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - OUTPUT_PATH  : {OUTPUT_PATH} [{'âœ… Exists' if OUTPUT_PATH.exists() else 'âš ï¸ Will be created'}]\")\n",
    "\n",
    "# 4. ì²´í¬í¬ì¸íŠ¸ í™•ì¸\n",
    "print(f\"\\n[4] ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ í™•ì¸\")\n",
    "print(f\"   - Checkpoint Dir : {CHECKPOINT_DIR} [{'âœ… Exists' if CHECKPOINT_DIR.exists() else 'âŒ Missing'}]\")\n",
    "print(f\"   - Checkpoint File: {CHECKPOINT_PT} [{'âœ… Exists' if CHECKPOINT_PT.exists() else 'âŒ Missing'}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# í•„ìˆ˜ ê²½ë¡œê°€ ì—†ì„ ê²½ìš° ê²½ê³  ë°œìƒ (ì„ íƒ ì‚¬í•­)\n",
    "if not video_path_obj.exists():\n",
    "    print(\"ğŸš¨ WARNING: ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\")\n",
    "if not CHECKPOINT_PT.exists():\n",
    "    print(\"ğŸš¨ WARNING: ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼(sam3.pt)ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8fcb4",
   "metadata": {},
   "source": [
    "## kptì—ì„œ Boundary Box ê°€ì§€ê³  ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(KPT_DIR / \"000000.json\", 'r') as f:\n",
    "    kpt_data = json.load(f)\n",
    "\n",
    "ori_bbox = kpt_data['instance_info'][0]['bbox'][0]\n",
    "ori_bbox = np.array(ori_bbox,dtype=np.float32)\n",
    "\n",
    "kpt_width, kpt_height = 1280, 720\n",
    "\n",
    "rel_box = [[\n",
    "    ori_bbox[0] / kpt_width,\n",
    "    ori_bbox[1] / kpt_height,\n",
    "    ori_bbox[2] / kpt_width,\n",
    "    ori_bbox[3] / kpt_height\n",
    "]]\n",
    "rel_box = np.array(rel_box,dtype=np.float32)\n",
    "\n",
    "print(\"Original BBox:\", ori_bbox)\n",
    "print(\"Relative BBox:\", rel_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07628279",
   "metadata": {},
   "source": [
    "## SAM3 ëª¨ë¸ ë¹Œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6660286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sam3.model_builder import build_sam3_video_model\n",
    "\n",
    "sam3_model = build_sam3_video_model(checkpoint_path=CHECKPOINT_PT)  # SAM3 ë¹„ë””ì˜¤ ëª¨ë¸ ë¹Œë“œ\n",
    "predictor = sam3_model.tracker                                      # SAM3 ë¹„ë””ì˜¤ ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”\n",
    "predictor.backbone = sam3_model.detector.backbone                   # ë°±ë³¸ ì„¤ì •\n",
    "\n",
    "print(\"SAM3 ë¹„ë””ì˜¤ ëª¨ë¸ê³¼ ì˜ˆì¸¡ê¸°ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a6a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_state = predictor.init_state(video_path=VIDEO_PTH)    # ë¹„ë””ì˜¤ ì¶”ë¡  ìƒíƒœ ì´ˆê¸°í™”\n",
    "predictor.clear_all_points_in_video(inference_state)            # ë¹„ë””ì˜¤ì˜ ëª¨ë“  í¬ì¸íŠ¸ ì§€ìš°ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc03f0ee",
   "metadata": {},
   "source": [
    "## ë¹„ë””ì˜¤ ê°€ì§€ê³  ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5251f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# load the frames for visualization\n",
    "cap = cv2.VideoCapture(VIDEO_PTH)       # ë¹„ë””ì˜¤ ì—´ê¸°\n",
    "video_frames_for_vis = []               #\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    video_frames_for_vis.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "cap.release()\n",
    "frame0 = video_frames_for_vis[0]\n",
    "\n",
    "width, height = frame0.shape[1], frame0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sam3.visualization_utils import show_box, show_mask\n",
    "ann_frame_idx = 0  # the frame index we interact with\n",
    "ann_obj_id = 4  # give a unique id to each object we interact with (it can be any integers)\n",
    "\n",
    "width = 1920\n",
    "height = 1080\n",
    "\n",
    "_, out_obj_ids, low_res_masks, video_res_masks  = predictor.add_new_points_or_box(\n",
    "    inference_state=inference_state,\n",
    "    frame_idx=ann_frame_idx,\n",
    "    obj_id=ann_obj_id,\n",
    "    box=rel_box,\n",
    ")\n",
    "\n",
    "box=np.array([[ \n",
    "    rel_box[0][0] * width,\n",
    "    rel_box[0][1] * height,\n",
    "    rel_box[0][2] * width,\n",
    "    rel_box[0][3] * height\n",
    "]], dtype=np.float32)\n",
    "\n",
    "\n",
    "# # show the results on the current (interacted) frame\n",
    "# plt.figure(figsize=(9, 6))\n",
    "# plt.title(f\"frame {ann_frame_idx}\")\n",
    "# plt.imshow(video_frames_for_vis[ann_frame_idx])\n",
    "# show_box(box[0], plt.gca())\n",
    "# show_mask((video_res_masks[0] > 0.0).cpu().numpy(), plt.gca(), obj_id=ann_obj_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207291e2",
   "metadata": {},
   "source": [
    "## segmentation ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37428eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "# run propagation throughout the video and collect the results in a dict\n",
    "video_segments = {}  # video_segments contains the per-frame segmentation results\n",
    "for frame_idx, obj_ids, low_res_masks, video_res_masks, obj_scores in predictor.propagate_in_video(inference_state, start_frame_idx=0, max_frame_num_to_track=N_FRAMES, reverse=False, propagate_preflight=True):\n",
    "    video_segments[frame_idx] = {\n",
    "        out_obj_id: (video_res_masks[i] > 0.0).cpu().numpy()\n",
    "        for i, out_obj_id in enumerate(out_obj_ids)\n",
    "    }\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Propagation completed in {elapsed_time:.2f} seconds for {N_FRAMES} frames.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845653fb",
   "metadata": {},
   "source": [
    "### JSON ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7bace1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sam3.model_builder import build_sam3_video_model\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append('/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_SAM3')\n",
    "from func.mask_to_bbox import mask_to_bbox\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ (Configuration & Data Loading)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Path ì •ë¦¬\n",
    "DATA_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data\")\n",
    "BASE_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_SAM3/\")\n",
    "CSV_PATH = DATA_DIR / \"metadata.csv\"\n",
    "OUTPUT_PATH = DATA_DIR / \"test\"\n",
    "CHECKPOINT_DIR = DATA_DIR / \"checkpoints/SAM3\"\n",
    "CHECKPOINT_PT = CHECKPOINT_DIR / \"sam3.pt\"\n",
    "\n",
    "# CSV ë¶ˆëŸ¬ì˜¤ê¸° ë° íƒ€ê²Ÿ ì„¤ì •\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# ì²˜ë¦¬í•  ì²­í¬ ì‚¬ì´ì¦ˆ ì„¤ì • (600 í”„ë ˆì„)\n",
    "CHUNK_SIZE = 600\n",
    "\n",
    "for target in range(0,1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ë°ì´í„° ì¶”ì¶œ\n",
    "    COMMON_PATH = df.loc[target, \"common_path\"]             # COMMON_PATH ì¶”ì¶œ\n",
    "    VIDEO_PTH = df.loc[target, \"video_path\"]\n",
    "    N_FRAMES = df.loc[target, \"n_frames\"]                   # í”„ë ˆì„ ìˆ˜ ì¶”ì¶œ\n",
    "\n",
    "    print(f\"segment video : {COMMON_PATH} (Total Frames: {N_FRAMES})\")\n",
    "\n",
    "    # ì„¸ë¶€ ê²½ë¡œ ì„¤ì •\n",
    "    FRAME_DIR = DATA_DIR / \"1_FRAME\" / COMMON_PATH          # í”„ë ˆì„ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "    KPT_DIR = DATA_DIR / \"2_KEYPOINTS\" / COMMON_PATH        # í‚¤í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "    MP4_PATH = DATA_DIR / \"3_MP4\" / f\"{COMMON_PATH}.mp4\"    # MP4 ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •    \n",
    "    INTERP_DIR = DATA_DIR / \"4_INTERP_DATA\" / COMMON_PATH   # ë³´ê°„ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "    SAVE_DIR = OUTPUT_PATH / COMMON_PATH                    # ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
    "    SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    JSON_SAVE_PATH = SAVE_DIR / \"video_segments.json\"\n",
    "    TIME_LOG_PATH = SAVE_DIR / \"elapsed_time.txt\"  # ì‹œê°„ ê¸°ë¡ì„ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # í•´ìƒë„ í™•ì¸ (Video Resolution Check) - bbox ê³„ì‚° ì „ì— í™•ì¸\n",
    "    # -------------------------------------------------------------------------\n",
    "    cap = cv2.VideoCapture(str(VIDEO_PTH))\n",
    "    if cap.isOpened():\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        cap.release()\n",
    "        print(f\"ğŸ¥ Detected Video Resolution: {width}x{height}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Warning: Could not open video at {VIDEO_PTH}. Using default 1920x1080.\")\n",
    "        width = 1920\n",
    "        height = 1080\n",
    "\n",
    "    # Keypoint ë°ì´í„° ë¡œë“œ ë° BBox ê³„ì‚°\n",
    "    with open(KPT_DIR / \"000000.json\", 'r') as f:\n",
    "        kpt_data = json.load(f)\n",
    "\n",
    "    ori_bbox = kpt_data['instance_info'][0]['bbox'][0]\n",
    "    ori_bbox = np.array(ori_bbox, dtype=np.float32)\n",
    "\n",
    "    kpt_width, kpt_height = 1280, 720\n",
    "\n",
    "    rel_box = [[\n",
    "        ori_bbox[0] / kpt_width,\n",
    "        ori_bbox[1] / kpt_height,\n",
    "        ori_bbox[2] / kpt_width,\n",
    "        ori_bbox[3] / kpt_height\n",
    "    ]]\n",
    "    rel_box = np.array(rel_box, dtype=np.float32)\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # 2. ëª¨ë¸ ì´ˆê¸°í™” (Model Initialization)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    sam3_model = build_sam3_video_model(checkpoint_path=CHECKPOINT_PT)  # SAM3 ë¹„ë””ì˜¤ ëª¨ë¸ ë¹Œë“œ\n",
    "    predictor = sam3_model.tracker                                      # SAM3 ë¹„ë””ì˜¤ ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”\n",
    "    predictor.backbone = sam3_model.detector.backbone                   # ë°±ë³¸ ì„¤ì •\n",
    "\n",
    "    print(\"SAM3 ë¹„ë””ì˜¤ ëª¨ë¸ê³¼ ì˜ˆì¸¡ê¸°ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # 3. ì¶”ë¡  ì¤€ë¹„ ë° í”„ë¡¬í”„íŠ¸ ì…ë ¥ (Inference Setup & Prompting)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    inference_state = predictor.init_state(video_path=VIDEO_PTH)    # ë¹„ë””ì˜¤ ì¶”ë¡  ìƒíƒœ ì´ˆê¸°í™”\n",
    "    predictor.clear_all_points_in_video(inference_state)            # ë¹„ë””ì˜¤ì˜ ëª¨ë“  í¬ì¸íŠ¸ ì§€ìš°ê¸°\n",
    "\n",
    "    ann_frame_idx = 0   # the frame index we interact with\n",
    "    ann_obj_id = 4      # give a unique id to each object we interact with\n",
    "\n",
    "    # ì´ˆê¸° í¬ì¸íŠ¸/ë°•ìŠ¤ ì¶”ê°€\n",
    "    _, out_obj_ids, low_res_masks, video_res_masks = predictor.add_new_points_or_box(\n",
    "        inference_state=inference_state,\n",
    "        frame_idx=ann_frame_idx,\n",
    "        obj_id=ann_obj_id,\n",
    "        box=rel_box,\n",
    "    )\n",
    "\n",
    "    # (ì°¸ê³ ìš©) ì‹¤ì œ í”½ì…€ ì¢Œí‘œ Box ê³„ì‚°\n",
    "    box = np.array([[ \n",
    "        rel_box[0][0] * width,\n",
    "        rel_box[0][1] * height,\n",
    "        rel_box[0][2] * width,\n",
    "        rel_box[0][3] * height\n",
    "    ]], dtype=np.float32)\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # 4. ë¹„ë””ì˜¤ ì „íŒŒ ë° ê²°ê³¼ ìˆ˜ì§‘ (Video Propagation with Chunks)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    video_segments = {}  # ì „ì²´ ê²°ê³¼ë¥¼ ëª¨ì„ ë”•ì…”ë„ˆë¦¬\n",
    "    \n",
    "    # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] 600 í”„ë ˆì„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ë£¨í”„ ì‹¤í–‰\n",
    "    # range(ì‹œì‘, ë, ê°„ê²©) -> 0, 600, 1200, ...\n",
    "    for start_idx in range(0, N_FRAMES, CHUNK_SIZE):\n",
    "        \n",
    "        # ì´ë²ˆ í„´ì— ì²˜ë¦¬í•  í”„ë ˆì„ ìˆ˜ ê³„ì‚° (ë§ˆì§€ë§‰ ì²­í¬ëŠ” 600ë³´ë‹¤ ì‘ì„ ìˆ˜ ìˆìŒ)\n",
    "        frames_to_track = min(CHUNK_SIZE, N_FRAMES - start_idx)\n",
    "        \n",
    "        print(f\"ğŸ”„ Processing Chunk: Frame {start_idx} ~ {start_idx + frames_to_track} (Size: {frames_to_track})\")\n",
    "\n",
    "        # propagate_in_video í˜¸ì¶œ\n",
    "        # start_frame_idxë¥¼ ì²­í¬ì˜ ì‹œì‘ì ìœ¼ë¡œ ì„¤ì •\n",
    "        # max_frame_num_to_trackì„ ì´ë²ˆ ì²­í¬ í¬ê¸°ë¡œ ì„¤ì •\n",
    "        for frame_idx, obj_ids, low_res_masks, video_res_masks, obj_scores in predictor.propagate_in_video(\n",
    "            inference_state,\n",
    "            start_frame_idx=start_idx,\n",
    "            max_frame_num_to_track=frames_to_track,\n",
    "            reverse=False,\n",
    "            propagate_preflight=True\n",
    "        ):\n",
    "            video_segments[frame_idx] = {\n",
    "                out_obj_id: (video_res_masks[i] > 0.0).cpu().numpy()\n",
    "                for i, out_obj_id in enumerate(out_obj_ids)\n",
    "            }\n",
    "        \n",
    "        # (ì„ íƒ ì‚¬í•­) í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ ë©”ëª¨ë¦¬ ì •ë¦¬(GC)ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë‚˜, \n",
    "        # SAMì˜ Tracking ì—°ì†ì„±ì„ ìœ„í•´ inference_stateëŠ” ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # 5. ê²°ê³¼ ë³€í™˜ ë° ì €ì¥ (Result Processing & Saving)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    print(\"ğŸ”„ JSON ë³€í™˜ ë° ì €ì¥ ì¤€ë¹„ ì¤‘...\")\n",
    "\n",
    "    json_output = {}\n",
    "\n",
    "    for frame_idx, segments in tqdm(video_segments.items()):\n",
    "        json_output[str(frame_idx)] = {} # JSON í‚¤ëŠ” ë¬¸ìì—´ì´ì–´ì•¼ ì•ˆì „í•¨\n",
    "        \n",
    "        for obj_id, mask in segments.items():\n",
    "            # ë§ˆìŠ¤í¬ ì°¨ì› ì •ë¦¬\n",
    "            if mask.ndim == 3:\n",
    "                mask = mask.squeeze()\n",
    "                \n",
    "            bbox = mask_to_bbox(mask)\n",
    "            \n",
    "            json_output[str(frame_idx)][str(obj_id)] = {\n",
    "                \"bbox\": bbox,\n",
    "            }\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì‹œì‘: {JSON_SAVE_PATH}\")\n",
    "        \n",
    "        with open(JSON_SAVE_PATH, 'w') as f:\n",
    "            json.dump(json_output, f) # indent=4ë¥¼ ë¹¼ë©´ ìš©ëŸ‰ì´ ì¤„ì–´ë“­ë‹ˆë‹¤.\n",
    "            \n",
    "        print(f\"âœ… ì €ì¥ ì™„ë£Œ! : {JSON_SAVE_PATH}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # 7. ì‹¤í–‰ ì‹œê°„ ë³„ë„ ì €ì¥ (Save Elapsed Time)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"ì´ ê±¸ë¦° ì‹œê°„ = {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    try:\n",
    "        with open(TIME_LOG_PATH, 'w') as f:\n",
    "            f.write(f\"Total execution time: {elapsed_time:.2f} seconds\\n\")  # ì‹œê°„ì„ ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ê¸°ë¡\n",
    "            f.write(f\"Processed Frames: {N_FRAMES}\\n\")\n",
    "            f.write(f\"Resolution: {width}x{height}\\n\")\n",
    "            f.write(f\"Chunk Size: {CHUNK_SIZE}\\n\") # ì²­í¬ ì‚¬ì´ì¦ˆë„ ê¸°ë¡\n",
    "            \n",
    "        print(f\"â±ï¸ ì‹¤í–‰ ì‹œê°„ ê¸°ë¡ ì €ì¥ ì™„ë£Œ: {TIME_LOG_PATH}\") \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹œê°„ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c601e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# ğŸ¯ ì‚¬ìš©ì ì§€ì •: ëŒ€ìƒ ì˜ìƒ ì´ë¦„ (í™•ì¥ì ì œì™¸)\n",
    "# -------------------------------------------------------\n",
    "target_video = \"M06_VISIT2_UpperLowerLimb\"\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# ğŸ§­ ê²½ë¡œ ì„¤ì •\n",
    "# -------------------------------------------------------\n",
    "BASE_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/data/d02/Won_Kim_research_at_Bosanjin/M06\")\n",
    "OutputRoot  = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/Won_Kim_research_at_Bosanjin/M06\")\n",
    "\n",
    "# ëŒ€ìƒ ì˜ìƒ íƒìƒ‰\n",
    "video_candidates = list(BASE_DIR.glob(f\"{target_video}.*\")) \n",
    "if not video_candidates:\n",
    "    raise FileNotFoundError(f\"âŒ ëŒ€ìƒ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤: {target_video}\")\n",
    "\n",
    "Input = video_candidates[0]\n",
    "OutputDir = OutputRoot / target_video\n",
    "OutputDir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\"\"\n",
    "ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ì • ì™„ë£Œ:\n",
    "   â€¢ Input Video : {Input}\n",
    "   â€¢ OutputDir   : {OutputDir}\n",
    "\"\"\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# âœ‚ï¸ ì„¸ê·¸ë¨¼íŠ¸ ì •ì˜ (frame ë‹¨ìœ„)\n",
    "# -------------------------------------------------------\n",
    "segments = [\n",
    "    (0*30,    35*30,   \"frontal__pec_dec_fly__1\"),        # 0ì´ˆ ~ 35ì´ˆ\n",
    "    (52*30,   100*30,  \"frontal__pec_dec_fly__2\"),        # 52ì´ˆ ~ 100ì´ˆ\n",
    "    (190*30,  235*30,  \"frontal__shoulder_press__1\"),     # 190ì´ˆ ~ 235ì´ˆ\n",
    "    (250*30,  290*30,  \"frontal__shoulder_press__2\"),     # 250ì´ˆ ~ 290ì´ˆ\n",
    "    (310*30,  347*30,  \"frontal__shoulder_flexion__1\"),   # 310ì´ˆ ~ 347ì´ˆ\n",
    "    (348*30,  370*30,  \"frontal__shoulder_flexion__2\"),   # 348ì´ˆ ~ 370ì´ˆ\n",
    "    (375*30,  400*30,  \"frontal__longsitting_knee_flexion__1\"), # 375ì´ˆ ~ 400ì´ˆ\n",
    "    (425*30,  470*30,  \"frontal__shoulder_flexion__3\"),   # 425ì´ˆ ~ 470ì´ˆ\n",
    "    (530*30,  560*30,  \"frontal__rowing__1\"),             # 530ì´ˆ ~ 560ì´ˆ\n",
    "    (590*30,  605*30,  \"frontal__rowing__2\"),             # 590ì´ˆ ~ 605ì´ˆ\n",
    "    (830*30,  975*30,  \"lateral__longsitting_knee_flexion__2\"), # 830ì´ˆ ~ 975ì´ˆ\n",
    "    (975*30,  1025*30, \"lateral__longsitting_knee_flexion__3\"), # 975ì´ˆ ~ 1025ì´ˆ\n",
    "    (1040*30, 1100*30, \"lateral__longsitting_knee_flexion__4\"), # 1040ì´ˆ ~ 1100ì´ˆ\n",
    "    (1120*30, 1165*30, \"lateral__slr__1\"),                # 1120ì´ˆ ~ 1165ì´ˆ\n",
    "    (1170*30, 1225*30, \"lateral__slr__2\"),                # 1170ì´ˆ ~ 1225ì´ˆ\n",
    "    (1240*30, 1290*30, \"lateral__slr__3\"),                # 1240ì´ˆ ~ 1290ì´ˆ\n",
    "    (1300*30, 1350*30, \"lateral__slr__4\"),                # 1300ì´ˆ ~ 1350ì´ˆ\n",
    "]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# ğŸ’¾ segmentation txt ì €ì¥\n",
    "# -------------------------------------------------------\n",
    "segment_txt = OutputDir / \"segment_frames.txt\"\n",
    "with open(segment_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# label, start_frame, end_frame\\n\")\n",
    "    for start, end, label in segments:\n",
    "        f.write(f\"{label}, {start}, {end}\\n\")\n",
    "\n",
    "print(f\"ğŸ“ segmentation info saved: {segment_txt}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# âœ‚ï¸ FFmpeg ì»·íŒ… í•¨ìˆ˜\n",
    "# -------------------------------------------------------\n",
    "def cut_video(input_video, start_frame, end_frame, output_video, fps=30):\n",
    "    \"\"\"FFmpegìœ¼ë¡œ mp4 êµ¬ê°„ ìë¥´ê¸° (frame ê¸°ë°˜, ì •í™•/ë¹ ë¦„/ë””ë²„ê¹… í¬í•¨)\"\"\"\n",
    "    def to_ffmpeg_time(frame_idx):\n",
    "        t = frame_idx / fps\n",
    "        m, s = divmod(t, 60)\n",
    "        return f\"{int(m):02d}:{int(s):02d}\"\n",
    "\n",
    "    start = to_ffmpeg_time(start_frame)\n",
    "    end = to_ffmpeg_time(end_frame)\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",\n",
    "        \"-ss\", start,\n",
    "        \"-to\", end,\n",
    "        \"-i\", str(input_video),\n",
    "        \"-c\", \"copy\",\n",
    "        str(output_video)\n",
    "    ]\n",
    "\n",
    "    print(f\"[DEBUG] ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}\")\n",
    "    proc = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if proc.returncode != 0:\n",
    "        print(f\"âŒ ffmpeg ì˜¤ë¥˜:\\n{proc.stderr}\")\n",
    "    else:\n",
    "        print(f\"âœ… ffmpeg ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë¨\")\n",
    "\n",
    "    if Path(output_video).exists():\n",
    "        size = Path(output_video).stat().st_size / 1024\n",
    "        print(f\"ğŸ“ íŒŒì¼ ìƒì„± í™•ì¸: {output_video} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {output_video}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# ğŸš€ ì»·íŒ… ì‹¤í–‰ (OutputDirì— ì§ì ‘ ì €ì¥)\n",
    "# -------------------------------------------------------\n",
    "for start, end, label in segments:\n",
    "    output_path = OutputDir / f\"{label}.mp4\"\n",
    "    cut_video(Input, start, end, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
