{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85a55017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Target: AI_dataset/N01/N01_Treatment/diagonal__biceps_curl\n",
      "[INFO] BBox Path: /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/test/AI_dataset/N01/N01_Treatment/diagonal__biceps_curl/video_segments.json\n",
      "[INFO] Save JSON Dir: /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/samplussapiens/AI_dataset/N01/N01_Treatment/diagonal__biceps_curl\n",
      "[INFO] í•´ìƒë„ ë³€í™˜: 1920x1080 -> 1280x720\n",
      "[INFO] Scale Factor: X=0.6667, Y=0.6667\n",
      "Loads checkpoint by local backend from path: /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/checkpoints/sapiens/pose/sapiens_0.3b_coco_best_coco_AP_796.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "missing keys in source state_dict: head.deconv_layers.1.weight, head.deconv_layers.1.bias, head.deconv_layers.1.running_mean, head.deconv_layers.1.running_var, head.deconv_layers.4.weight, head.deconv_layers.4.bias, head.deconv_layers.4.running_mean, head.deconv_layers.4.running_var, head.conv_layers.1.weight, head.conv_layers.1.bias, head.conv_layers.1.running_mean, head.conv_layers.1.running_var, head.conv_layers.4.weight, head.conv_layers.4.bias, head.conv_layers.4.running_mean, head.conv_layers.4.running_var\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sapiens Processing:  18% 430/2432 [03:43<17:24,  1.92it/s]/opt/conda/lib/python3.10/site-packages/mmpose/structures/bbox/transforms.py:357: RuntimeWarning: divide by zero encountered in divide\n",
      "  scale_x = (output_size[0] - 1) / scale[0]\n",
      "/opt/conda/lib/python3.10/site-packages/mmpose/structures/bbox/transforms.py:358: RuntimeWarning: divide by zero encountered in divide\n",
      "  scale_y = (output_size[1] - 1) / scale[1]\n",
      "/opt/conda/lib/python3.10/site-packages/mmpose/structures/bbox/transforms.py:360: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  warp_mat[0, 1] = -math.sin(rot_rad) * scale_x\n",
      "/opt/conda/lib/python3.10/site-packages/mmpose/structures/bbox/transforms.py:361: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  warp_mat[0, 2] = scale_x * (-0.5 * input_size[0] * math.cos(rot_rad) +\n",
      "/opt/conda/lib/python3.10/site-packages/mmpose/structures/bbox/transforms.py:364: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  warp_mat[1, 0] = math.sin(rot_rad) * scale_y\n",
      "/opt/conda/lib/python3.10/site-packages/mmpose/structures/bbox/transforms.py:366: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  warp_mat[1, 2] = scale_y * (-0.5 * input_size[0] * math.sin(rot_rad) -\n",
      "Sapiens Processing: 100% 2432/2432 [21:08<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ…] Keypoint ì¶”ì¶œ ì™„ë£Œ: 2432 frames saved in /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/samplussapiens/AI_dataset/N01/N01_Treatment/diagonal__biceps_curl\n",
      "\n",
      "[ğŸ ì™„ë£Œ] JSON ì €ì¥ ìœ„ì¹˜: /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/samplussapiens/AI_dataset/N01/N01_Treatment/diagonal__biceps_curl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# MMPOSE ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from mmpose.apis import init_model as init_pose_estimator, inference_topdown\n",
    "from mmpose.structures import merge_data_samples, split_instances\n",
    "\n",
    "# ====================================================\n",
    "# 1. ì„¤ì • ë° ê²½ë¡œ ì •ì˜\n",
    "# ====================================================\n",
    "DATA_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data\")\n",
    "BASE_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_sam3/\")\n",
    "CSV_PATH = DATA_DIR / \"metadata.csv\"\n",
    "\n",
    "# Sapiens Config & Checkpoint\n",
    "POSE_CFG = \"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_sapiens_labeling/configs/sapiens/sapiens_0.3b-210e_coco-1024x768.py\"\n",
    "POSE_CKPT = DATA_DIR / \"checkpoints/sapiens/pose/sapiens_0.3b_coco_best_coco_AP_796.pth\"\n",
    "\n",
    "# CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "target = 0\n",
    "COMMON_PATH = df.loc[target, \"common_path\"]\n",
    "VIDEO_PTH = df.loc[target, \"video_path\"]\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "FRAME_DIR = DATA_DIR / \"1_FRAME\" / COMMON_PATH\n",
    "SAVE_JSON_DIR = DATA_DIR / \"samplussapiens\" / COMMON_PATH\n",
    "BBOX_PATH = DATA_DIR / \"test\" / COMMON_PATH / \"video_segments.json\"\n",
    "\n",
    "print(f\"[INFO] Target: {COMMON_PATH}\")\n",
    "print(f\"[INFO] BBox Path: {BBOX_PATH}\")\n",
    "print(f\"[INFO] Save JSON Dir: {SAVE_JSON_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (âœ… ì¬ê·€ì  ë³€í™˜ ê¸°ëŠ¥ ì¶”ê°€ - ìˆ˜ì •ë¨)\n",
    "# ====================================================\n",
    "def to_py(obj):\n",
    "    \"\"\"\n",
    "    ë³µì¡í•œ ì¤‘ì²© êµ¬ì¡°(dict, list) ë‚´ì˜ ëª¨ë“  NumPy íƒ€ì…ì„ \n",
    "    JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ì¬ê·€ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, (np.float32, np.float64, np.floating)):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, (np.int32, np.int64, np.integer)):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: to_py(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [to_py(v) for v in obj]\n",
    "    return obj\n",
    "\n",
    "# ====================================================\n",
    "# 3. Sapiens ì¶”ì¶œ í•¨ìˆ˜\n",
    "# ====================================================\n",
    "def run_sapiens_with_scaled_bbox(\n",
    "    frame_dir, json_out_dir, bbox_path, pose_cfg, pose_ckpt, \n",
    "    device=\"cuda:0\", \n",
    "    orig_w=1920, orig_h=1080\n",
    "):\n",
    "    frame_dir, json_out_dir = Path(frame_dir), Path(json_out_dir)\n",
    "    bbox_path = Path(bbox_path)\n",
    "\n",
    "    # 1. BBox JSON ë¡œë“œ\n",
    "    if not bbox_path.exists():\n",
    "        print(f\"[ERROR] BBox íŒŒì¼ ì—†ìŒ: {bbox_path}\")\n",
    "        return\n",
    "    with open(bbox_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        bbox_data = json.load(f)\n",
    "\n",
    "    # 2. ê²°ê³¼ í´ë” ì´ˆê¸°í™”\n",
    "    if json_out_dir.exists():\n",
    "        shutil.rmtree(json_out_dir)\n",
    "    json_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 3. í˜„ì¬ í”„ë ˆì„ í•´ìƒë„ í™•ì¸ ë° ìŠ¤ì¼€ì¼ ê³„ì‚°\n",
    "    frame_files = sorted(list(frame_dir.glob(\"*.jpg\")))\n",
    "    if not frame_files:\n",
    "        print(\"[ERROR] í”„ë ˆì„ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    sample_img = cv2.imread(str(frame_files[0]))\n",
    "    curr_h, curr_w = sample_img.shape[:2]\n",
    "\n",
    "    scale_x = curr_w / orig_w\n",
    "    scale_y = curr_h / orig_h\n",
    "    \n",
    "    print(f\"[INFO] í•´ìƒë„ ë³€í™˜: {orig_w}x{orig_h} -> {curr_w}x{curr_h}\")\n",
    "    print(f\"[INFO] Scale Factor: X={scale_x:.4f}, Y={scale_y:.4f}\")\n",
    "\n",
    "    # 4. ëª¨ë¸ ë¡œë“œ\n",
    "    pose_estimator = init_pose_estimator(\n",
    "        str(pose_cfg), str(pose_ckpt), device=device,\n",
    "        cfg_options=dict(model=dict(test_cfg=dict(output_heatmaps=False)))\n",
    "    )\n",
    "\n",
    "    # 5. ì¶”ë¡  ë£¨í”„ (Sequential)\n",
    "    saved_count = 0\n",
    "    \n",
    "    for fpath in tqdm(frame_files, desc=\"Sapiens Processing\"):\n",
    "        frame_idx_str = str(int(fpath.stem)) # \"000123\" -> \"123\"\n",
    "\n",
    "        # 1) BBox ì •ë³´ í™•ì¸\n",
    "        if frame_idx_str not in bbox_data:\n",
    "            continue\n",
    "        \n",
    "        instances = bbox_data[frame_idx_str]\n",
    "        if not instances:\n",
    "            continue\n",
    "\n",
    "        # 2) BBox ìŠ¤ì¼€ì¼ë§ ë° ìˆ˜ì§‘\n",
    "        frame_boxes = []\n",
    "        for _, val in instances.items():\n",
    "            if \"bbox\" in val:\n",
    "                box = np.array(val[\"bbox\"], dtype=np.float32)\n",
    "                box[0] *= scale_x\n",
    "                box[1] *= scale_y\n",
    "                box[2] *= scale_x\n",
    "                box[3] *= scale_y\n",
    "                frame_boxes.append(box)\n",
    "\n",
    "        if not frame_boxes:\n",
    "            continue\n",
    "        \n",
    "        # numpy ë³€í™˜ (N, 4)\n",
    "        bbox_np = np.array(frame_boxes)\n",
    "\n",
    "        try:\n",
    "            # ë‹¨ì¼ í”„ë ˆì„ ì¶”ë¡ \n",
    "            results = inference_topdown(pose_estimator, str(fpath), bbox_np)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Inference failed for {fpath.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 3) ê²°ê³¼ ì €ì¥\n",
    "        for res in results:\n",
    "            data_sample = merge_data_samples([res])\n",
    "            inst = data_sample.get(\"pred_instances\", None)\n",
    "            \n",
    "            if inst is None: continue\n",
    "            inst_list = split_instances(inst)\n",
    "\n",
    "            payload = {\n",
    "                \"frame_index\": int(fpath.stem),\n",
    "                \"meta_info\": pose_estimator.dataset_meta, # ì—¬ê¸°ì— numpyê°€ ì„ì—¬ìˆìŒ\n",
    "                \"instance_info\": inst_list,               # ì—¬ê¸°ì—ë„ numpyê°€ ì„ì—¬ìˆìŒ\n",
    "                \"source\": \"scaled_bbox_json\"\n",
    "            }\n",
    "            \n",
    "            out_path = json_out_dir / f\"{fpath.stem}.json\"\n",
    "            \n",
    "            # âœ… to_pyê°€ ì´ì œ ì¬ê·€ì ìœ¼ë¡œ ëŒë©´ì„œ ëª¨ë“  numpyë¥¼ ì œê±°í•¨\n",
    "            with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(to_py(payload), f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            saved_count += 1\n",
    "\n",
    "    print(f\"[âœ…] Keypoint ì¶”ì¶œ ì™„ë£Œ: {saved_count} frames saved in {json_out_dir}\")\n",
    "\n",
    "# ====================================================\n",
    "# 4. ì‹¤í–‰\n",
    "# ====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_sapiens_with_scaled_bbox(\n",
    "        frame_dir=FRAME_DIR,\n",
    "        json_out_dir=SAVE_JSON_DIR,\n",
    "        bbox_path=BBOX_PATH,\n",
    "        pose_cfg=POSE_CFG,\n",
    "        pose_ckpt=POSE_CKPT,\n",
    "        orig_w=1920, \n",
    "        orig_h=1080\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[ğŸ ì™„ë£Œ] JSON ì €ì¥ ìœ„ì¹˜: {SAVE_JSON_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f9259",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpt_path = \"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/samplussapiens/AI_dataset/N01/N01_Treatment/diagonal__biceps_curl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c5566e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Frames: /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/1_FRAME/AI_dataset/N01/N01_Treatment/diagonal__biceps_curl\n",
      "[INFO] JSONs:  /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/samplussapiens/AI_dataset/N01/N01_Treatment/diagonal__biceps_curl\n",
      "[INFO] Output: /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/test/AI_dataset/N01/N01_Treatment/diagonal__biceps_curl_overlay.mp4\n",
      "[INFO] Starting rendering... (1280x720 @ 30fps)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering Video: 100% 2432/2432 [00:27<00:00, 89.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Video saved to: /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/test/AI_dataset/N01/N01_Treatment/diagonal__biceps_curl_overlay.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# ====================================================\n",
    "# 1. Settings & Paths\n",
    "# ====================================================\n",
    "DATA_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data\")\n",
    "CSV_PATH = DATA_DIR / \"metadata.csv\"\n",
    "\n",
    "# Load Metadata\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "target = 0\n",
    "COMMON_PATH = df.loc[target, \"common_path\"]\n",
    "\n",
    "# Define Paths\n",
    "FRAME_DIR = DATA_DIR / \"1_FRAME\" / COMMON_PATH\n",
    "KPT_DIR = DATA_DIR / \"samplussapiens\" / COMMON_PATH\n",
    "OUTPUT_VIDEO_PATH = DATA_DIR / \"test\" / f\"{COMMON_PATH}_overlay.mp4\"\n",
    "\n",
    "# Visualization Settings\n",
    "BBOX_COLOR = (0, 255, 0)      # Green\n",
    "BBOX_THICKNESS = 2\n",
    "SKELETON_THICKNESS = 2\n",
    "KEYPOINT_RADIUS = 4\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# âœ… ì¤‘ìš”: ì ìˆ˜ê°€ ë‚®ì•„ë„ ë³´ì´ê²Œ í•˜ê¸° ìœ„í•´ 0.0ìœ¼ë¡œ ì„¤ì • (ê¸°ì¡´ 0.3 -> 0.0)\n",
    "CONF_THRESHOLD = 0.0 \n",
    "\n",
    "print(f\"[INFO] Frames: {FRAME_DIR}\")\n",
    "print(f\"[INFO] JSONs:  {KPT_DIR}\")\n",
    "print(f\"[INFO] Output: {OUTPUT_VIDEO_PATH}\")\n",
    "\n",
    "# ====================================================\n",
    "# 2. Rendering Function\n",
    "# ====================================================\n",
    "def render_video(frame_dir, json_dir, output_path, fps=30):\n",
    "    frame_dir = Path(frame_dir)\n",
    "    json_dir = Path(json_dir)\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    frame_files = sorted(list(frame_dir.glob(\"*.jpg\")))\n",
    "    if not frame_files:\n",
    "        print(\"[ERROR] No frames found.\")\n",
    "        return\n",
    "\n",
    "    first_frame = cv2.imread(str(frame_files[0]))\n",
    "    height, width, _ = first_frame.shape\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "\n",
    "    print(f\"[INFO] Starting rendering... ({width}x{height} @ {fps}fps)\")\n",
    "\n",
    "    for frame_path in tqdm(frame_files, desc=\"Rendering Video\"):\n",
    "        frame = cv2.imread(str(frame_path))\n",
    "        if frame is None: continue\n",
    "            \n",
    "        frame_idx_str = frame_path.stem\n",
    "        json_path = json_dir / f\"{frame_idx_str}.json\"\n",
    "\n",
    "        if json_path.exists():\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            meta = data.get(\"meta_info\", {})\n",
    "            skeleton_links = meta.get(\"skeleton_links\", [])\n",
    "            link_colors = meta.get(\"skeleton_link_colors\", [])\n",
    "            kpt_colors = meta.get(\"keypoint_colors\", [])\n",
    "\n",
    "            instances = data.get(\"instance_info\", [])\n",
    "            for inst in instances:\n",
    "                # 1. Draw Bounding Box\n",
    "                if \"bbox\" in inst:\n",
    "                    bbox = inst[\"bbox\"]\n",
    "                    if isinstance(bbox[0], list): \n",
    "                        bbox = bbox[0]\n",
    "                    x1, y1, x2, y2 = map(int, bbox)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), BBOX_COLOR, BBOX_THICKNESS)\n",
    "\n",
    "                # 2. Draw Skeleton & Keypoints\n",
    "                if \"keypoints\" in inst:\n",
    "                    kpts = np.array(inst[\"keypoints\"])\n",
    "                    scores = inst.get(\"keypoint_scores\", np.ones(len(kpts)))\n",
    "\n",
    "                    # Draw Links\n",
    "                    for idx, link in enumerate(skeleton_links):\n",
    "                        i, j = link\n",
    "                        if i >= len(kpts) or j >= len(kpts): continue\n",
    "                        \n",
    "                        # âœ… ìˆ˜ì •ë¨: CONF_THRESHOLD ë³€ìˆ˜ ì‚¬ìš© (0.0 ì´ìƒì´ë©´ ê·¸ë¦¬ê¸°)\n",
    "                        if scores[i] < CONF_THRESHOLD or scores[j] < CONF_THRESHOLD: continue\n",
    "\n",
    "                        pt1 = tuple(map(int, kpts[i]))\n",
    "                        pt2 = tuple(map(int, kpts[j]))\n",
    "                        \n",
    "                        color = tuple(link_colors[idx]) if idx < len(link_colors) else (255, 0, 0)\n",
    "                        color = color[::-1] \n",
    "                        cv2.line(frame, pt1, pt2, color, SKELETON_THICKNESS)\n",
    "\n",
    "                    # Draw Points\n",
    "                    for i, (x, y) in enumerate(kpts):\n",
    "                        # âœ… ìˆ˜ì •ë¨: CONF_THRESHOLD ë³€ìˆ˜ ì‚¬ìš©\n",
    "                        if scores[i] < CONF_THRESHOLD: continue\n",
    "                        \n",
    "                        color = tuple(kpt_colors[i]) if i < len(kpt_colors) else (0, 0, 255)\n",
    "                        color = color[::-1]\n",
    "                        cv2.circle(frame, (int(x), int(y)), KEYPOINT_RADIUS, color, -1)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"[DONE] Video saved to: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    render_video(FRAME_DIR, KPT_DIR, OUTPUT_VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eca3c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì˜ìƒ ë³€í™˜ ì‹œì‘: diagonal__hip_extension.mp4\n",
      "ğŸ“‚ ì €ì¥ ê²½ë¡œ: /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/test/frame_change\n",
      "â„¹ï¸ ì›ë³¸ ì •ë³´: 1920x1080 @ 29.97002997002997fps\n",
      "   - ì¤€ë¹„ë¨: diagonal__hip_extension_1280x720.mp4\n",
      "   - ì¤€ë¹„ë¨: diagonal__hip_extension_1024x576.mp4\n",
      "   - ì¤€ë¹„ë¨: diagonal__hip_extension_640x360.mp4\n",
      "   - ì¤€ë¹„ë¨: diagonal__hip_extension_480x270.mp4\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100% 320/320 [00:11<00:00, 27.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "âœ… ëª¨ë“  ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ====================================================\n",
    "# 1. Settings & Paths\n",
    "# ====================================================\n",
    "DATA_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data\")\n",
    "CSV_PATH = DATA_DIR / \"metadata.csv\"\n",
    "\n",
    "# Load Metadata\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "target = 1\n",
    "VIDEO_PTH = Path(df.loc[target, \"video_path\"])\n",
    "\n",
    "# ì €ì¥í•  í´ë” ì„¤ì •\n",
    "OUTPUT_VIDEO_DIR = DATA_DIR / \"test\" / \"frame_change\"\n",
    "OUTPUT_VIDEO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸš€ ì˜ìƒ ë³€í™˜ ì‹œì‘: {VIDEO_PTH.name}\")\n",
    "print(f\"ğŸ“‚ ì €ì¥ ê²½ë¡œ: {OUTPUT_VIDEO_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# 2. Resizing Logic\n",
    "# ====================================================\n",
    "def resize_video_multi_output(input_path, output_dir):\n",
    "    # 1. ë¹„ë””ì˜¤ ì—´ê¸°\n",
    "    cap = cv2.VideoCapture(str(input_path))\n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # ì›ë³¸ ì •ë³´ ì½ê¸°\n",
    "    org_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    org_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"â„¹ï¸ ì›ë³¸ ì •ë³´: {org_width}x{org_height} @ {fps}fps\")\n",
    "\n",
    "    # 2. ëª©í‘œ í•´ìƒë„ 4ê°œ ì •ì˜ (ë„ˆë¹„, ë†’ì´) - 16:9 ë¹„ìœ¨ ìœ ì§€\n",
    "    # SAM ë“±ì— ë„£ê¸° ì¢‹ì€ ì‚¬ì´ì¦ˆë“¤ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.\n",
    "    target_resolutions = [\n",
    "        (1280, 720),  # HD (720p)\n",
    "        (1024, 576),  # SAM ì¹œí™”ì  ë„ˆë¹„ (1024px)\n",
    "        (640, 360),   # nHD (360p) - ì†ë„ ë§¤ìš° ë¹ ë¦„\n",
    "        (480, 270)    # ì €í•´ìƒë„ - í…ŒìŠ¤íŠ¸ìš©\n",
    "    ]\n",
    "\n",
    "    # 3. Writer ê°ì²´ë“¤ ì´ˆê¸°í™”\n",
    "    writers = []\n",
    "    \n",
    "    for w, h in target_resolutions:\n",
    "        # íŒŒì¼ëª… ìë™ ìƒì„± (ì˜ˆ: video_1280x720.mp4)\n",
    "        out_name = output_dir / f\"{input_path.stem}_{w}x{h}.mp4\"\n",
    "        \n",
    "        # MP4 ì½”ë± ì„¤ì •\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        writer = cv2.VideoWriter(str(out_name), fourcc, fps, (w, h))\n",
    "        \n",
    "        if not writer.isOpened():\n",
    "            print(f\"âŒ Writer ì´ˆê¸°í™” ì‹¤íŒ¨: {out_name}\")\n",
    "            return\n",
    "            \n",
    "        writers.append(writer)\n",
    "        print(f\"   - ì¤€ë¹„ë¨: {out_name.name}\")\n",
    "\n",
    "    # 4. í”„ë ˆì„ ì²˜ë¦¬ ë£¨í”„ (í•œ ë²ˆ ì½ì–´ì„œ ë„¤ ë²ˆ ì“°ê¸°)\n",
    "    print(\"-\" * 60)\n",
    "    pbar = tqdm(total=total_frames, desc=\"Processing\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # ê° í•´ìƒë„ë³„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ í›„ ì €ì¥\n",
    "        for idx, (w, h) in enumerate(target_resolutions):\n",
    "            # ë¦¬ì‚¬ì´ì¦ˆ (AREA ë³´ê°„ë²•ì´ ì¶•ì†Œ ì‹œ í™”ì§ˆì´ ê°€ì¥ ì¢‹ìŒ)\n",
    "            resized_frame = cv2.resize(frame, (w, h), interpolation=cv2.INTER_AREA)\n",
    "            writers[idx].write(resized_frame)\n",
    "            \n",
    "        pbar.update(1)\n",
    "\n",
    "    # 5. ìì› í•´ì œ\n",
    "    cap.release()\n",
    "    for writer in writers:\n",
    "        writer.release()\n",
    "    pbar.close()\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(\"âœ… ëª¨ë“  ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "resize_video_multi_output(VIDEO_PTH, OUTPUT_VIDEO_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
