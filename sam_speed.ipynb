{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a69f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ë²¤ì¹˜ë§ˆí‚¹ & ì‹œê°í™” ì‹œì‘: AI_dataset/N01/N01_Treatment/diagonal__hip_extension\n",
      "ğŸ“‚ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data/test/benchmark_overlay_result\n",
      "\n",
      "[Init] SAM 3 ëª¨ë¸ ë¡œë“œ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-12-18 12:07:08,560 121 sam3_video_base.py: 124:\u001b[0m setting max_num_objects=10000 and num_obj_for_compile=16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Start] ì´ 4ê°œ ì˜ìƒ í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "------------------------------------------------------------\n",
      "ğŸ‘‰ Testing: diagonal__hip_extension_640x360.mp4 (640x360, 320 frames)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "propagate in video: 100% 320/320 [06:52<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ì™„ë£Œ! Inf Time: 361.58s | FPS: 0.88\n",
      "   ğŸ’¾ ì˜ìƒ ì €ì¥: overlay_diagonal__hip_extension_640x360.mp4\n",
      "ğŸ‘‰ Testing: diagonal__hip_extension_480x270.mp4 (480x270, 320 frames)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "propagate in video: 100% 320/320 [06:26<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ì™„ë£Œ! Inf Time: 363.98s | FPS: 0.88\n",
      "   ğŸ’¾ ì˜ìƒ ì €ì¥: overlay_diagonal__hip_extension_480x270.mp4\n",
      "ğŸ‘‰ Testing: diagonal__hip_extension_1280x720.mp4 (1280x720, 320 frames)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "propagate in video: 100% 320/320 [06:28<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ì™„ë£Œ! Inf Time: 363.66s | FPS: 0.88\n",
      "   ğŸ’¾ ì˜ìƒ ì €ì¥: overlay_diagonal__hip_extension_1280x720.mp4\n",
      "ğŸ‘‰ Testing: diagonal__hip_extension_1024x576.mp4 (1024x576, 320 frames)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "propagate in video: 100% 320/320 [06:53<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ì™„ë£Œ! Inf Time: 360.36s | FPS: 0.89\n",
      "   ğŸ’¾ ì˜ìƒ ì €ì¥: overlay_diagonal__hip_extension_1024x576.mp4\n",
      "\n",
      "============================================================\n",
      "                                   File Resolution  Inference Time(s)   FPS  \\\n",
      "0   diagonal__hip_extension_640x360.mp4    640x360             361.58  0.88   \n",
      "1   diagonal__hip_extension_480x270.mp4    480x270             363.98  0.88   \n",
      "2  diagonal__hip_extension_1280x720.mp4   1280x720             363.66  0.88   \n",
      "3  diagonal__hip_extension_1024x576.mp4   1024x576             360.36  0.89   \n",
      "\n",
      "   Frames  \n",
      "0     320  \n",
      "1     320  \n",
      "2     320  \n",
      "3     320  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sam3.model_builder import build_sam3_video_model\n",
    "\n",
    "# ====================================================\n",
    "# 1. ì„¤ì • ë° ê²½ë¡œ\n",
    "# ====================================================\n",
    "DATA_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data\")\n",
    "CSV_PATH = DATA_DIR / \"metadata.csv\"\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "target = 1  \n",
    "COMMON_PATH = df.loc[target, \"common_path\"]\n",
    "VIDEO_DIR = DATA_DIR / \"test\" / \"frame_change\"\n",
    "KPT_DIR = DATA_DIR / \"2_KEYPOINTS\" / COMMON_PATH\n",
    "CHECKPOINT_PT = DATA_DIR / \"checkpoints/SAM3/sam3.pt\"\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ í´ë”\n",
    "OUTPUT_RESULT_DIR = DATA_DIR / \"test\" / \"benchmark_overlay_result\"\n",
    "OUTPUT_RESULT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸš€ ë²¤ì¹˜ë§ˆí‚¹ & ì‹œê°í™” ì‹œì‘: {COMMON_PATH}\")\n",
    "print(f\"ğŸ“‚ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {OUTPUT_RESULT_DIR}\")\n",
    "\n",
    "# ====================================================\n",
    "# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜: ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´\n",
    "# ====================================================\n",
    "def apply_mask_overlay(image, mask, color=(0, 255, 0), alpha=0.5):\n",
    "    \"\"\"ì´ë¯¸ì§€ì— ì´ì§„ ë§ˆìŠ¤í¬ë¥¼ ë°˜íˆ¬ëª…í•˜ê²Œ ë®ì–´ì”Œì›ë‹ˆë‹¤.\"\"\"\n",
    "    if mask.ndim != 2: return image\n",
    "    \n",
    "    overlay = image.copy()\n",
    "    overlay[mask > 0] = color\n",
    "    \n",
    "    output = image.copy()\n",
    "    output[mask > 0] = cv2.addWeighted(image, 1-alpha, overlay, alpha, 0)[mask > 0]\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(output, contours, -1, (255, 255, 255), 1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# ====================================================\n",
    "# 3. ì´ˆê¸° ì„¤ì • (BBox ë¡œë“œ ë° ëª¨ë¸ ì¤€ë¹„)\n",
    "# ====================================================\n",
    "REF_W, REF_H = 1280, 720 # Keypoint ê¸°ì¤€ í•´ìƒë„\n",
    "\n",
    "with open(KPT_DIR / \"000000.json\", 'r') as f:\n",
    "    kpt_data = json.load(f)\n",
    "\n",
    "raw_bbox = kpt_data['instance_info'][0]['bbox'][0]\n",
    "rel_bbox = [\n",
    "    raw_bbox[0] / REF_W,\n",
    "    raw_bbox[1] / REF_H,\n",
    "    raw_bbox[2] / REF_W,\n",
    "    raw_bbox[3] / REF_H\n",
    "]\n",
    "\n",
    "print(f\"\\n[Init] SAM 3 ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "sam3_model = build_sam3_video_model(checkpoint_path=CHECKPOINT_PT)\n",
    "predictor = sam3_model.tracker\n",
    "predictor.backbone = sam3_model.detector.backbone\n",
    "\n",
    "# ====================================================\n",
    "# 4. ë²¤ì¹˜ë§ˆí‚¹ ë£¨í”„\n",
    "# ====================================================\n",
    "video_files = list(VIDEO_DIR.glob(\"*.mp4\"))\n",
    "results = []\n",
    "\n",
    "print(f\"\\n[Start] ì´ {len(video_files)}ê°œ ì˜ìƒ í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for vid_path in sorted(video_files, reverse=True):\n",
    "    # ë¹„ë””ì˜¤ ì •ë³´ ì½ê¸°\n",
    "    cap = cv2.VideoCapture(str(vid_path))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"ğŸ‘‰ Testing: {vid_path.name} ({width}x{height}, {total_frames} frames)\")\n",
    "    \n",
    "    save_name = OUTPUT_RESULT_DIR / f\"overlay_{vid_path.name}\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(save_name), fourcc, fps, (width, height))\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬ (OOM ë°©ì§€)\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    try:\n",
    "        # 1. ì´ˆê¸°í™”\n",
    "        inference_state = predictor.init_state(\n",
    "            video_path=str(vid_path),\n",
    "            offload_video_to_cpu=True,\n",
    "            async_loading_frames=True\n",
    "        )\n",
    "        predictor.clear_all_points_in_video(inference_state)\n",
    "        \n",
    "        # 2. í”„ë¡¬í”„íŠ¸\n",
    "        abs_box = np.array([[\n",
    "            rel_bbox[0] * width, rel_bbox[1] * height,\n",
    "            rel_bbox[2] * width, rel_bbox[3] * height\n",
    "        ]], dtype=np.float32)\n",
    "        \n",
    "        predictor.add_new_points_or_box(\n",
    "            inference_state=inference_state,\n",
    "            frame_idx=0,\n",
    "            obj_id=1,\n",
    "            box=abs_box\n",
    "        )\n",
    "        \n",
    "        # 3. ì¶”ë¡  ë° ì €ì¥ ë£¨í”„\n",
    "        pure_inference_time = 0\n",
    "        frame_cnt = 0\n",
    "        \n",
    "        iterator = predictor.propagate_in_video(\n",
    "            inference_state, \n",
    "            start_frame_idx=0,\n",
    "            max_frame_num_to_track=total_frames,\n",
    "            reverse=False,\n",
    "            propagate_preflight=True\n",
    "        )\n",
    "        \n",
    "        while True:\n",
    "            t0 = time.time()\n",
    "            try:\n",
    "                step_result = next(iterator)\n",
    "                \n",
    "                if len(step_result) >= 4:\n",
    "                    out_frame_idx = step_result[0]\n",
    "                    out_obj_ids = step_result[1]\n",
    "                    out_mask_logits = step_result[3] \n",
    "                else:\n",
    "                    out_frame_idx, out_obj_ids, out_mask_logits = step_result[:3]\n",
    "\n",
    "            except StopIteration:\n",
    "                break\n",
    "            except ValueError as ve: \n",
    "                print(f\"âš ï¸ ë¦¬í„´ê°’ ì–¸íŒ¨í‚¹ ì—ëŸ¬: {ve}\")\n",
    "                break\n",
    "\n",
    "            pure_inference_time += (time.time() - t0)\n",
    "            frame_cnt += 1\n",
    "            \n",
    "            # --- ì‹œê°í™” ---\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            \n",
    "            for i, obj_id in enumerate(out_obj_ids):\n",
    "                if obj_id == 1:\n",
    "                    mask = (out_mask_logits[i] > 0.0).cpu().numpy().squeeze()\n",
    "                    if mask.ndim == 2:\n",
    "                        frame = apply_mask_overlay(frame, mask, color=(0, 255, 0), alpha=0.6)\n",
    "            \n",
    "            cv2.putText(frame, f\"SAM 3 | {width}x{height}\", (20, 40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "            out.write(frame)\n",
    "            # -------------\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        fps = frame_cnt / pure_inference_time if pure_inference_time > 0 else 0\n",
    "        print(f\"   âœ… ì™„ë£Œ! Inf Time: {pure_inference_time:.2f}s | FPS: {fps:.2f}\")\n",
    "        print(f\"   ğŸ’¾ ì˜ìƒ ì €ì¥: {save_name.name}\")\n",
    "        \n",
    "        results.append({\n",
    "            \"File\": vid_path.name,\n",
    "            \"Resolution\": f\"{width}x{height}\",\n",
    "            \"Inference Time(s)\": round(pure_inference_time, 2),\n",
    "            \"FPS\": round(fps, 2),\n",
    "            \"Frames\": frame_cnt\n",
    "        })\n",
    "        \n",
    "        # ğŸ’¡ [ìˆ˜ì •ë¨] reset_state ì œê±°, delë¡œë§Œ ì •ë¦¬\n",
    "        del inference_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() \n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "# ====================================================\n",
    "# 5. ë¦¬í¬íŠ¸ ì €ì¥\n",
    "# ====================================================\n",
    "df_res = pd.DataFrame(results).sort_values(\"FPS\", ascending=True)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(df_res)\n",
    "df_res.to_csv(OUTPUT_RESULT_DIR / \"benchmark_overlay_report.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
