from pathlib import Path
import pandas as pd
import json
import time
from tqdm import tqdm
import numpy as np
from sam3.model_builder import build_sam3_video_model
import sys
sys.path.append('/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_sam3')
from func.mask_to_bbox import mask_to_bbox

# -----------------------------------------------------------------------------
# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ (Configuration & Data Loading)
# -----------------------------------------------------------------------------

# Path ì •ë¦¬
DATA_DIR = Path("/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data")
BASE_DIR = Path("/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_sam3/")
CSV_PATH = DATA_DIR / "metadata.csv"
OUTPUT_PATH = DATA_DIR / "test"
CHECKPOINT_DIR = DATA_DIR / "checkpoints/SAM3"
CHECKPOINT_PT = CHECKPOINT_DIR / "sam3.pt"

# CSV ë¶ˆëŸ¬ì˜¤ê¸° ë° íƒ€ê²Ÿ ì„¤ì •
df = pd.read_csv(CSV_PATH)
target = 3                             # ì›í•˜ëŠ” í–‰ ì¸ë±ìŠ¤ ì„¤ì •

for target in range(1,2):
    start_time = time.time()

    # ë°ì´í„° ì¶”ì¶œ
    COMMON_PATH = df.loc[target, "common_path"]   # COMMON_PATH ì¶”ì¶œ
    VIDEO_PTH = df.loc[target, "video_path"]
    N_FRAMES = df.loc[target, "n_frames"]         # í”„ë ˆì„ ìˆ˜ ì¶”ì¶œ

    print("segment video : ", COMMON_PATH)

    # ì„¸ë¶€ ê²½ë¡œ ì„¤ì •
    FRAME_DIR = DATA_DIR / "1_FRAME" / COMMON_PATH          # í”„ë ˆì„ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
    KPT_DIR = DATA_DIR / "2_KEYPOINTS" / COMMON_PATH        # í‚¤í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
    MP4_PATH = DATA_DIR / "3_MP4" / f"{COMMON_PATH}.mp4"    # MP4 ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •    
    INTERP_DIR = DATA_DIR / "4_INTERP_DATA" / COMMON_PATH   # ë³´ê°„ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
    SAVE_DIR = OUTPUT_PATH / COMMON_PATH                    # ì €ì¥ ê²½ë¡œ ì„¤ì •
    SAVE_DIR.mkdir(parents=True, exist_ok=True)
    JSON_SAVE_PATH = SAVE_DIR / "video_segments.json"
    TIME_LOG_PATH = SAVE_DIR / "elapsed_time.txt"  # ì‹œê°„ ê¸°ë¡ì„ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ ì„¤ì •

    # Keypoint ë°ì´í„° ë¡œë“œ ë° BBox ê³„ì‚°
    with open(KPT_DIR / "000000.json", 'r') as f:
        kpt_data = json.load(f)

    ori_bbox = kpt_data['instance_info'][0]['bbox'][0]
    ori_bbox = np.array(ori_bbox, dtype=np.float32)

    kpt_width, kpt_height = 1280, 720

    rel_box = [[
        ori_bbox[0] / kpt_width,
        ori_bbox[1] / kpt_height,
        ori_bbox[2] / kpt_width,
        ori_bbox[3] / kpt_height
    ]]
    rel_box = np.array(rel_box, dtype=np.float32)

    # -----------------------------------------------------------------------------
    # 2. ëª¨ë¸ ì´ˆê¸°í™” (Model Initialization)
    # -----------------------------------------------------------------------------
    sam3_model = build_sam3_video_model(checkpoint_path=CHECKPOINT_PT)  # SAM3 ë¹„ë””ì˜¤ ëª¨ë¸ ë¹Œë“œ
    predictor = sam3_model.tracker                                      # SAM3 ë¹„ë””ì˜¤ ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
    predictor.backbone = sam3_model.detector.backbone                   # ë°±ë³¸ ì„¤ì •

    print("SAM3 ë¹„ë””ì˜¤ ëª¨ë¸ê³¼ ì˜ˆì¸¡ê¸°ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # -----------------------------------------------------------------------------
    # 3. ì¶”ë¡  ì¤€ë¹„ ë° í”„ë¡¬í”„íŠ¸ ì…ë ¥ (Inference Setup & Prompting)
    # -----------------------------------------------------------------------------
    inference_state = predictor.init_state(video_path=VIDEO_PTH)    # ë¹„ë””ì˜¤ ì¶”ë¡  ìƒíƒœ ì´ˆê¸°í™”
    predictor.clear_all_points_in_video(inference_state)            # ë¹„ë””ì˜¤ì˜ ëª¨ë“  í¬ì¸íŠ¸ ì§€ìš°ê¸°

    ann_frame_idx = 0   # the frame index we interact with
    ann_obj_id = 4      # give a unique id to each object we interact with

    # ì´ˆê¸° í¬ì¸íŠ¸/ë°•ìŠ¤ ì¶”ê°€
    _, out_obj_ids, low_res_masks, video_res_masks = predictor.add_new_points_or_box(
        inference_state=inference_state,
        frame_idx=ann_frame_idx,
        obj_id=ann_obj_id,
        box=rel_box,
    )

    # í•´ìƒë„ ë³µì›ìš© ë³€ìˆ˜ (ì‚¬ìš©ì ì½”ë“œ ìœ ì§€)
    width = 1920
    height = 1080

    box = np.array([[ 
        rel_box[0][0] * width,
        rel_box[0][1] * height,
        rel_box[0][2] * width,
        rel_box[0][3] * height
    ]], dtype=np.float32)

    # -----------------------------------------------------------------------------
    # 4. ë¹„ë””ì˜¤ ì „íŒŒ ë° ê²°ê³¼ ìˆ˜ì§‘ (Video Propagation)
    # -----------------------------------------------------------------------------
    video_segments = {}  # video_segments contains the per-frame segmentation results

    # run propagation throughout the video and collect the results in a dict
    for frame_idx, obj_ids, low_res_masks, video_res_masks, obj_scores in predictor.propagate_in_video(inference_state, start_frame_idx=0, max_frame_num_to_track=N_FRAMES, reverse=False, propagate_preflight=True):
        video_segments[frame_idx] = {
            out_obj_id: (video_res_masks[i] > 0.0).cpu().numpy()
            for i, out_obj_id in enumerate(out_obj_ids)
        }

    # -----------------------------------------------------------------------------
    # 5. ê²°ê³¼ ë³€í™˜ ë° ì €ì¥ (Result Processing & Saving)
    # -----------------------------------------------------------------------------
    print("ğŸ”„ JSON ë³€í™˜ ë° ì €ì¥ ì¤€ë¹„ ì¤‘...")

    json_output = {}

    for frame_idx, segments in tqdm(video_segments.items()):
        json_output[str(frame_idx)] = {} # JSON í‚¤ëŠ” ë¬¸ìì—´ì´ì–´ì•¼ ì•ˆì „í•¨
        
        for obj_id, mask in segments.items():
            # ë§ˆìŠ¤í¬ ì°¨ì› ì •ë¦¬
            if mask.ndim == 3:
                mask = mask.squeeze()
                
            bbox = mask_to_bbox(mask)
            
            json_output[str(frame_idx)][str(obj_id)] = {
                "bbox": bbox,
            }

    try:
        print(f"ğŸ’¾ JSON íŒŒì¼ ì €ì¥ ì‹œì‘: {JSON_SAVE_PATH}")
        
        with open(JSON_SAVE_PATH, 'w') as f:
            json.dump(json_output, f) # indent=4ë¥¼ ë¹¼ë©´ ìš©ëŸ‰ì´ ì¤„ì–´ë“­ë‹ˆë‹¤.
            
        print(f"âœ… ì €ì¥ ì™„ë£Œ! : {JSON_SAVE_PATH}")
        
    except Exception as e:
        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")

    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"ì´ ê±¸ë¦° ì‹œê°„ = {elapsed_time:.2f} seconds")
    # -----------------------------------------------------------------------------
    # 7. ì‹¤í–‰ ì‹œê°„ ë³„ë„ ì €ì¥ (Save Elapsed Time)
    # -----------------------------------------------------------------------------

    try:
        with open(TIME_LOG_PATH, 'w') as f:
            f.write(f"Total execution time: {elapsed_time:.2f} seconds\n")  # ì‹œê°„ì„ ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ê¸°ë¡
            f.write(f"Processed Frames: {N_FRAMES}\n")  # (ì„ íƒì‚¬í•­) ì²˜ë¦¬í•œ í”„ë ˆì„ ìˆ˜ë„ í•¨ê»˜ ì ìœ¼ë©´ ë¶„ì„ì— ë” ì¢‹ìŠµë‹ˆë‹¤.
            
        print(f"â±ï¸ ì‹¤í–‰ ì‹œê°„ ê¸°ë¡ ì €ì¥ ì™„ë£Œ: {TIME_LOG_PATH}")  # ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥

    except Exception as e:
        print(f"âŒ ì‹œê°„ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")  # ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬